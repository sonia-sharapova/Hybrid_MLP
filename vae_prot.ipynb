{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a95ce1-a2c3-4f47-903d-5442f51c112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import scipy.sparse as sp\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07dbbda-5ae0-4954-9cf1-bed140f11cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1377fb0b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31e2bae-8ccc-4d0a-bf00-ea8a65a53a08",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8675d207-113b-4b3c-bcc0-6b4656f0e894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A1BG     A2M   A2ML1    AAAS  AACS   AAED1   AAGAB    AAK1   AAMDC  \\\n",
      "0    0.7618  0.7481  0.0000  1.3759   0.0  0.0000  0.0000  0.0160  0.0000   \n",
      "1    1.4195  0.9259  0.0000  0.6716   0.0  0.0000  0.0808  0.1219  0.0000   \n",
      "2    0.3180  0.0000  0.0000  0.1638   0.0  0.0000  0.4738  0.0433  0.0000   \n",
      "3    0.0128  0.0000  0.0000  0.3808   0.0  0.3719  0.0000  0.0169  0.0000   \n",
      "4    0.0000  0.1080  0.0000  0.0000   0.0  0.0000  0.1073  0.0000  0.0000   \n",
      "..      ...     ...     ...     ...   ...     ...     ...     ...     ...   \n",
      "100  0.0771  0.0000  0.7431  0.2510   0.0  0.0000  0.0000  0.1511  0.0000   \n",
      "101  0.0997  0.0000  0.0000  0.0000   0.0  0.0296  0.1863  0.1723  0.0922   \n",
      "102  0.7527  0.5561  3.3277  0.8935   0.0  0.0000  0.0000  0.0975  0.0000   \n",
      "103  0.0126  0.0000  0.0000  0.0796   0.0  0.0000  0.0000  0.2538  0.0000   \n",
      "104  0.9947  0.4070  0.0000  0.1486   0.0  0.0000  0.0000  0.2440  0.0000   \n",
      "\n",
      "       AAMP  ...  ZSWIM8    ZW10  ZWILCH   ZWINT    ZXDC  ZYG11B     ZYX  \\\n",
      "0    0.0000  ...  0.4656  0.2251  0.7310  0.0000  0.0000  1.1508  0.0000   \n",
      "1    0.2943  ...  0.2386  0.0193  0.0000  0.0000  0.0000  0.6027  0.0000   \n",
      "2    0.3008  ...  0.0000  0.0000  0.2109  0.2311  0.0000  0.2617  0.3484   \n",
      "3    0.0000  ...  0.0927  0.2363  0.7675  0.6338  0.0000  0.1919  0.3602   \n",
      "4    0.4147  ...  0.0000  0.0000  0.0000  0.1598  0.5379  0.0397  0.0925   \n",
      "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "100  0.0000  ...  0.1084  0.0598  0.0921  0.0000  0.1626  0.0000  0.0000   \n",
      "101  0.0727  ...  0.1842  0.0000  0.0000  0.1901  0.1515  0.2357  0.0000   \n",
      "102  0.0000  ...  0.4146  0.0000  0.9516  0.6781  0.0000  1.3542  0.0000   \n",
      "103  0.0994  ...  0.0000  0.0000  0.3311  0.0874  0.0000  0.0000  0.0000   \n",
      "104  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.3986  0.0251   \n",
      "\n",
      "      ZZEF1    ZZZ3  cancer_type  \n",
      "0    0.0132  1.6853            1  \n",
      "1    0.0000  0.9144            3  \n",
      "2    0.0000  0.0087            2  \n",
      "3    0.0000  0.3334            1  \n",
      "4    0.0000  0.1183            4  \n",
      "..      ...     ...          ...  \n",
      "100  0.0586  0.2732            1  \n",
      "101  0.0000  0.0072            4  \n",
      "102  0.0000  0.0000            1  \n",
      "103  0.0628  0.4018            4  \n",
      "104  0.0000  0.2670            3  \n",
      "\n",
      "[105 rows x 9734 columns]\n"
     ]
    }
   ],
   "source": [
    "pd_celldata = pd.read_csv(\"proteinOutFileCat_nn.csv\", sep=',', header=0)\n",
    "#pd_celldata = pd.read_csv(\"rnaSeqOutFileCat_nn.csv\", sep=',', header=0)\n",
    "pd_celldata = pd_celldata.rename({'Cancer Type': 'cancer_type'}, axis=1)\n",
    "\n",
    "pd_celldata_t = pd_celldata.drop(columns=\"Composite.Element.REF\")\n",
    "#pd_celldata_t = pd_celldata.drop(columns=\"Hugo_Symbol\")\n",
    "\n",
    "celldata_t = pd_celldata.to_numpy()\n",
    "features = list(pd_celldata)\n",
    "\n",
    "numlist=[]\n",
    "labels = []\n",
    "for ind in range(celldata_t.shape[0]):\n",
    "    x = celldata_t[ind,:]\n",
    "    numlist.append(x)\n",
    "    labels.append(x[-1])\n",
    "\n",
    "numlist = np.array(numlist)\n",
    "print(pd_celldata_t)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = pd_celldata_t.drop(labels='cancer_type', axis=1),pd_celldata_t['cancer_type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3,\n",
    "    stratify=y, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71daed21",
   "metadata": {},
   "source": [
    "## Baseline Gene Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd201ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "Mean Squared Error: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier  # for classification tasks\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def randomForestBaseline(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust hyperparameters like n_estimators\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean Squared Error: {mse:.2f}')\n",
    "    \n",
    "    importances = clf.feature_importances_\n",
    "    feature_names = list(pd_celldata_t.columns)  # Replace with your actual feature names or column labels\n",
    "\n",
    "    # Create a list of (importance, feature_name) tuples\n",
    "    feature_importance_tuples = list(zip(importances, feature_names))\n",
    "    \n",
    "    check = feature_importance_tuples.copy()\n",
    "\n",
    "    # Sort the feature importances in descending order\n",
    "    feature_importance_tuples.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "    # Print or access the ranked list of features\n",
    "    ranked_features = []\n",
    "    for importance, feature_name in feature_importance_tuples:\n",
    "        ranked_features.append((feature_name, importance))\n",
    "    \n",
    "    return ranked_features\n",
    "\n",
    "ranked_features = randomForestBaseline(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b6902-fa66-45bc-b5c0-5fb7ebac6bc3",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "645b62e9-9747-422c-a8eb-8253fcacc470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.9.6 anndata==0.10.3 umap==0.5.4 numpy==1.24.3 scipy==1.11.1 pandas==2.0.3 scikit-learn==1.3.0 statsmodels==0.14.0 pynndescent==0.5.10\n"
     ]
    }
   ],
   "source": [
    "X_train_norm1 = X_train.div(X_train.sum(axis=1), axis=0)\n",
    "X_train_norm2 = X_train.div(X_train.sum(axis=0), axis=1)\n",
    "X_train_norm2=X_train_norm2.fillna(0)\n",
    "\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor=\"white\")\n",
    "\n",
    "X_train_a = np.array(X_train_norm1)\n",
    "adata = ad.AnnData(X_train_a)\n",
    "#adata.uns[\"name\"] = \"rna_seq\"\n",
    "adata.uns[\"name\"] = \"prot\"\n",
    "\n",
    "y_train_str = []\n",
    "for i in y_train:\n",
    "    y_train_str.append(str(i)) # convert to strings so that they can be recognized by scanpy\n",
    "adata.obs['true_labels'] = y_train_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e1b502-bfb5-4099-8811-c6c18ba026a3",
   "metadata": {},
   "source": [
    "## preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce26650d-f8a3-4ef8-a62f-0c11fb9fd8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   true_labels\n",
       "0            1\n",
       "1            3\n",
       "2            1\n",
       "3            3\n",
       "4            3\n",
       "..         ...\n",
       "68           3\n",
       "69           0\n",
       "70           4\n",
       "71           4\n",
       "72           3\n",
       "\n",
       "[73 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef03d9de-6476-45bc-9f52-361d344d1bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X_train.iloc[idx].values  # Extract values from X_train DataFrame row\n",
    "        y = self.y_train.iloc[idx]  # Extract label from y_train DataFrame\n",
    "        return torch.tensor(X, dtype=torch.float), torch.tensor(y, dtype=torch.long)  # Convert to PyTorch tensors\n",
    "\n",
    "def preprocess(adata):\n",
    "    sc.pp.filter_genes(adata, min_cells=1)\n",
    "    sc.pp.normalize_total(adata)\n",
    "    sc.pp.neighbors(adata, use_rep='X')\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca459746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an Autoencoder (AE) model \n",
    "\n",
    "##### Original ####\n",
    "\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 4*1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*1024, 4*512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*512, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 4*512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*512, 4*1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*1024, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent_representation = self.encoder(x)\n",
    "        recon_batch = self.decoder(latent_representation)\n",
    "        return recon_batch, latent_representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771e49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f8a7607-65e4-4d1b-b0b8-8f5d072447d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a Multi-Layer Perceptron (MLP) model \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_prob=0.5):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.dropout = nn.Dropout(dropout_prob)  # Dropout layer\n",
    "        self.fc3 = nn.Linear(256, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Combine AE and MLP models\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, ae, mlp):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.ae = ae\n",
    "        self.mlp = mlp\n",
    "    \n",
    "    def forward(self, x):\n",
    "        recon_batch, latent_representation = self.ae(x)\n",
    "        mlp_output = self.mlp(latent_representation)\n",
    "        return recon_batch, mlp_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfaccc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "#input_dim = len(adata.var)\n",
    "input_dim = len(numlist[0]) - 2\n",
    "\n",
    "output_dim = 5\n",
    "#reaches 78.12% with output_dim=10 but stabalizes at 75%\n",
    "batch_size = 757\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "# Initialize AE and MLP models with increased complexity and dropout\n",
    "ae = AE(input_dim, latent_dim)\n",
    "mlp = MLP(latent_dim, output_dim)\n",
    "\n",
    "# Create the combined model\n",
    "combined_model = CombinedModel(ae, mlp)\n",
    "\n",
    "autoencoder_criterion = nn.MSELoss()\n",
    "mlp_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_combined = optim.AdamW(combined_model.parameters(), lr=0.001)\n",
    "\n",
    "# Initialize the learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer_combined, step_size=5, gamma=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96b34287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data loaders\n",
    "\n",
    "X_df_train = pd.DataFrame(X_train)\n",
    "y_df_train = pd.Series(y_train)\n",
    "\n",
    "dataset_train = MyDataset(X_df_train, y_df_train)\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "X_df_test = pd.DataFrame(X_test)\n",
    "y_df_test = pd.Series(y_test)\n",
    "\n",
    "dataset_test = MyDataset(X_df_test, y_df_test)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10468319-da59-4ba2-a702-2475e9c9a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_loss(autoencoder_loss, mlp_loss, custom_loss_weight):\n",
    "    return autoencoder_loss + mlp_loss + (custom_loss_weight * custom_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f01ed723-3ad8-4a2c-828f-a70b27ab68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom MSE loss function.\n",
    "class CustomMSELoss(nn.Module):\n",
    "    def __init__(self, gene_ranking, gene_importance_threshold, learning_rate):\n",
    "        super(CustomMSELoss, self).__init__()\n",
    "        self.gene_ranking = nn.Parameter(gene_ranking.clone().detach(), requires_grad=True)\n",
    "        self.gene_importance_threshold = gene_importance_threshold\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, predicted, target):\n",
    "        mse_loss = torch.mean((predicted - target)**2)\n",
    "\n",
    "        # Penalize less important genes\n",
    "        gene_penalty = torch.sum(torch.relu(self.gene_ranking - self.gene_importance_threshold))\n",
    "        total_loss = mse_loss + gene_penalty\n",
    "\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af884fcc-3617-47d4-bb56-ff8af0528e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Batch [0/1], AE Loss: 0.2168, MLP Loss: 1.6082\n",
      "Epoch [1/50], Combined Model Accuracy on Validation/Test dataset: 31.25%\n",
      "Epoch [2/50], Batch [0/1], AE Loss: 0.1500, MLP Loss: 1.5045\n",
      "Epoch [2/50], Combined Model Accuracy on Validation/Test dataset: 28.12%\n",
      "Epoch [3/50], Batch [0/1], AE Loss: 0.1481, MLP Loss: 2.2803\n",
      "Epoch [3/50], Combined Model Accuracy on Validation/Test dataset: 40.62%\n",
      "Epoch [4/50], Batch [0/1], AE Loss: 0.1571, MLP Loss: 1.3515\n",
      "Epoch [4/50], Combined Model Accuracy on Validation/Test dataset: 50.00%\n",
      "Epoch [5/50], Batch [0/1], AE Loss: 0.1431, MLP Loss: 1.2311\n",
      "Epoch [5/50], Combined Model Accuracy on Validation/Test dataset: 53.12%\n",
      "Epoch [6/50], Batch [0/1], AE Loss: 0.1412, MLP Loss: 1.0072\n",
      "Epoch [6/50], Combined Model Accuracy on Validation/Test dataset: 53.12%\n",
      "Epoch [7/50], Batch [0/1], AE Loss: 0.1394, MLP Loss: 0.8908\n",
      "Epoch [7/50], Combined Model Accuracy on Validation/Test dataset: 53.12%\n",
      "Epoch [8/50], Batch [0/1], AE Loss: 0.1369, MLP Loss: 0.7853\n",
      "Epoch [8/50], Combined Model Accuracy on Validation/Test dataset: 53.12%\n",
      "Epoch [9/50], Batch [0/1], AE Loss: 0.1344, MLP Loss: 0.6870\n",
      "Epoch [9/50], Combined Model Accuracy on Validation/Test dataset: 68.75%\n",
      "Epoch [10/50], Batch [0/1], AE Loss: 0.1324, MLP Loss: 0.5765\n",
      "Epoch [10/50], Combined Model Accuracy on Validation/Test dataset: 68.75%\n",
      "Epoch [11/50], Batch [0/1], AE Loss: 0.1290, MLP Loss: 0.4517\n",
      "Epoch [11/50], Combined Model Accuracy on Validation/Test dataset: 68.75%\n",
      "Epoch [12/50], Batch [0/1], AE Loss: 0.1262, MLP Loss: 0.3896\n",
      "Epoch [12/50], Combined Model Accuracy on Validation/Test dataset: 68.75%\n",
      "Epoch [13/50], Batch [0/1], AE Loss: 0.1236, MLP Loss: 0.3294\n",
      "Epoch [13/50], Combined Model Accuracy on Validation/Test dataset: 68.75%\n",
      "Epoch [14/50], Batch [0/1], AE Loss: 0.1229, MLP Loss: 0.2709\n",
      "Epoch [14/50], Combined Model Accuracy on Validation/Test dataset: 75.00%\n",
      "Epoch [15/50], Batch [0/1], AE Loss: 0.1200, MLP Loss: 0.2196\n",
      "Epoch [15/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [16/50], Batch [0/1], AE Loss: 0.1169, MLP Loss: 0.1814\n",
      "Epoch [16/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [17/50], Batch [0/1], AE Loss: 0.1158, MLP Loss: 0.1641\n",
      "Epoch [17/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [18/50], Batch [0/1], AE Loss: 0.1145, MLP Loss: 0.1472\n",
      "Epoch [18/50], Combined Model Accuracy on Validation/Test dataset: 68.75%\n",
      "Epoch [19/50], Batch [0/1], AE Loss: 0.1129, MLP Loss: 0.1325\n",
      "Epoch [19/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [20/50], Batch [0/1], AE Loss: 0.1116, MLP Loss: 0.1203\n",
      "Epoch [20/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [21/50], Batch [0/1], AE Loss: 0.1104, MLP Loss: 0.1101\n",
      "Epoch [21/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [22/50], Batch [0/1], AE Loss: 0.1096, MLP Loss: 0.1053\n",
      "Epoch [22/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [23/50], Batch [0/1], AE Loss: 0.1086, MLP Loss: 0.1006\n",
      "Epoch [23/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [24/50], Batch [0/1], AE Loss: 0.1076, MLP Loss: 0.0959\n",
      "Epoch [24/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [25/50], Batch [0/1], AE Loss: 0.1067, MLP Loss: 0.0913\n",
      "Epoch [25/50], Combined Model Accuracy on Validation/Test dataset: 75.00%\n",
      "Epoch [26/50], Batch [0/1], AE Loss: 0.1056, MLP Loss: 0.0869\n",
      "Epoch [26/50], Combined Model Accuracy on Validation/Test dataset: 75.00%\n",
      "Epoch [27/50], Batch [0/1], AE Loss: 0.1051, MLP Loss: 0.0846\n",
      "Epoch [27/50], Combined Model Accuracy on Validation/Test dataset: 75.00%\n",
      "Epoch [28/50], Batch [0/1], AE Loss: 0.1045, MLP Loss: 0.0823\n",
      "Epoch [28/50], Combined Model Accuracy on Validation/Test dataset: 75.00%\n",
      "Epoch [29/50], Batch [0/1], AE Loss: 0.1039, MLP Loss: 0.0800\n",
      "Epoch [29/50], Combined Model Accuracy on Validation/Test dataset: 75.00%\n",
      "Epoch [30/50], Batch [0/1], AE Loss: 0.1033, MLP Loss: 0.0775\n",
      "Epoch [30/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [31/50], Batch [0/1], AE Loss: 0.1027, MLP Loss: 0.0750\n",
      "Epoch [31/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [32/50], Batch [0/1], AE Loss: 0.1024, MLP Loss: 0.0738\n",
      "Epoch [32/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [33/50], Batch [0/1], AE Loss: 0.1021, MLP Loss: 0.0726\n",
      "Epoch [33/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [34/50], Batch [0/1], AE Loss: 0.1018, MLP Loss: 0.0714\n",
      "Epoch [34/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [35/50], Batch [0/1], AE Loss: 0.1015, MLP Loss: 0.0702\n",
      "Epoch [35/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [36/50], Batch [0/1], AE Loss: 0.1012, MLP Loss: 0.0690\n",
      "Epoch [36/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [37/50], Batch [0/1], AE Loss: 0.1010, MLP Loss: 0.0684\n",
      "Epoch [37/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [38/50], Batch [0/1], AE Loss: 0.1009, MLP Loss: 0.0679\n",
      "Epoch [38/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [39/50], Batch [0/1], AE Loss: 0.1007, MLP Loss: 0.0673\n",
      "Epoch [39/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [40/50], Batch [0/1], AE Loss: 0.1006, MLP Loss: 0.0667\n",
      "Epoch [40/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [41/50], Batch [0/1], AE Loss: 0.1004, MLP Loss: 0.0662\n",
      "Epoch [41/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [42/50], Batch [0/1], AE Loss: 0.1003, MLP Loss: 0.0659\n",
      "Epoch [42/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [43/50], Batch [0/1], AE Loss: 0.1002, MLP Loss: 0.0656\n",
      "Epoch [43/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [44/50], Batch [0/1], AE Loss: 0.1002, MLP Loss: 0.0654\n",
      "Epoch [44/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [45/50], Batch [0/1], AE Loss: 0.1001, MLP Loss: 0.0651\n",
      "Epoch [45/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [46/50], Batch [0/1], AE Loss: 0.1000, MLP Loss: 0.0648\n",
      "Epoch [46/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [47/50], Batch [0/1], AE Loss: 0.1000, MLP Loss: 0.0647\n",
      "Epoch [47/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [48/50], Batch [0/1], AE Loss: 0.0999, MLP Loss: 0.0646\n",
      "Epoch [48/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [49/50], Batch [0/1], AE Loss: 0.0999, MLP Loss: 0.0644\n",
      "Epoch [49/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n",
      "Epoch [50/50], Batch [0/1], AE Loss: 0.0998, MLP Loss: 0.0643\n",
      "Epoch [50/50], Combined Model Accuracy on Validation/Test dataset: 71.88%\n"
     ]
    }
   ],
   "source": [
    "gene_importance_threshold = 0.1\n",
    "#custom_loss = CustomMSELoss(ordered, gene_importance_threshold, learning_rate)\n",
    "\n",
    "num_epochs = 50\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (X_train, y_train) in enumerate(train_loader):\n",
    "        X_train = X_train.view(X_train.size(0), -1)\n",
    "\n",
    "        optimizer_combined.zero_grad()\n",
    "        #X_train = X_train.view(batch_size, 1, 73, 9733)\n",
    "\n",
    "        recon_batch, mlp_output_train = combined_model(X_train)\n",
    "\n",
    "        # Calculate AE loss (reconstruction loss)\n",
    "        #ae_loss = custom_loss(recon_batch, data)\n",
    "        \n",
    "        ae_loss = nn.MSELoss()(recon_batch, X_train)\n",
    "\n",
    "        # Calculate MLP loss \n",
    "        mlp_loss = nn.CrossEntropyLoss()(mlp_output_train, y_train)\n",
    "\n",
    "        # Total loss\n",
    "        total_loss = ae_loss + mlp_loss\n",
    "\n",
    "        optimizer_combined.zero_grad()\n",
    "        total_loss.backward(retain_graph=True)\n",
    "\n",
    "\n",
    "        optimizer_combined.step()\n",
    "\n",
    "        #ordered.grad = torch.autograd.grad(ae_loss, custom_loss.gene_ranking)[0]\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], AE Loss: {ae_loss.item():.4f}, MLP Loss: {mlp_loss.item():.4f}')\n",
    "\n",
    "    # Step the learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Evaluate accuracy on validation/test dataset\n",
    "    combined_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in test_loader:  \n",
    "            X_test = X_test.view(X_test.size(0), -1)\n",
    "            _, mlp_output = combined_model(X_test)\n",
    "            _, predicted = torch.max(mlp_output, 1)\n",
    "            total += y_test.size(0)\n",
    "            correct += (predicted == y_test).sum().item()\n",
    "\n",
    "\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Combined Model Accuracy on Validation/Test dataset: {100 * accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913849ca-07fa-4073-ae99-03941543fa43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329a5c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc708de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96218948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d00a2e7-0a96-4a08-8fc9-1e47da717827",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ordered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Forward pass, compute loss, and backpropagate\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Use the custom loss function with the current gene rankings\u001b[39;00m\n\u001b[1;32m     12\u001b[0m optimizer_combined\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m gene_rankings \u001b[38;5;241m=\u001b[39m ordered\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m recon_batch, mlp_output \u001b[38;5;241m=\u001b[39m combined_model(data)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(recon_batch)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ordered' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convergence criteria\n",
    "max_iterations = 10  # Adjust as needed\n",
    "convergence_threshold = 0.001  # Adjust as needed\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    # Train the model with the current gene rankings\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "            data = data.view(data.size(0), -1)\n",
    "            # Forward pass, compute loss, and backpropagate\n",
    "            # Use the custom loss function with the current gene rankings\n",
    "            optimizer_combined.zero_grad()\n",
    "            gene_rankings = ordered.clone().detach().requires_grad_(True)\n",
    "            recon_batch, mlp_output = combined_model(data)\n",
    "            print(recon_batch)\n",
    "            print(mlp_output)\n",
    "            print(labels)\n",
    "            loss = CustomLoss(ordered)(latent_representation, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Check for convergence by comparing updated gene rankings\n",
    "        new_gene_rankings = ordered.detach().numpy()\n",
    "        if torch.norm(new_gene_rankings - ordered) < convergence_threshold:\n",
    "            break  # Converged\n",
    "\n",
    "        # Update gene rankings based on the current model (you can define your update logic)\n",
    "        ordered = new_gene_rankings\n",
    "\n",
    "# Final gene rankings after convergence\n",
    "final_gene_rankings = new_gene_rankings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4101957-8a61-46c3-ab28-109aab99edb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5567921-9a13-47f2-bc59-5fe76bd748d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ae_loss)\n",
    "print(mlp_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdaffd-7881-4d2d-b4b6-e631c499d3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0243ac54-c063-4ff5-97ca-93f1802cbe49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4c7f0-5540-4f65-a3e3-71157d53c9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a2c38-62c0-4637-8357-284f836cc051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64a7ed8-3d97-4a95-8f97-3178fffeaf68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa11a55-10bb-4b3d-b50c-37586dc5d2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85db08cb-e347-48a4-aa6a-67c838a65a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45142d33-07b9-47c2-99fc-5febb4dac542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf499d-551d-4087-98d5-8b99c1bd5167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ad93b-c9fb-4723-937c-2b37d2e0f301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1479225-77bb-4a0d-b2d8-581c7e094650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc9c82b-9767-4165-a00b-bece705e2b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e07fc2-0ef6-4500-901e-866335c2a2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
